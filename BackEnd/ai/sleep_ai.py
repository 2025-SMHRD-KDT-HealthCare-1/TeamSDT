# sleep_ai.py - ìµœì í™” ë²„ì „ (ëª¨ë¸ 1íšŒ ë¡œë”©)

import os
from pathlib import Path
import numpy as np
import faiss
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer, CrossEncoder
import google.generativeai as genai

from gtts import gTTS
from io import BytesIO
import base64
import warnings
warnings.filterwarnings("ignore")

# --------------------------
# ğŸ”¥ 1) í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
# --------------------------
BASE_DIR = Path(__file__).resolve().parent.parent
load_dotenv(BASE_DIR / ".env")

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
genai.configure(api_key=GEMINI_API_KEY)

model = genai.GenerativeModel("gemini-2.5-flash")


# --------------------------
# ğŸ”¥ 2) ë¬¸ì„œ ë¡œë“œ (1íšŒ)
# --------------------------
AI_DIR = Path(__file__).resolve().parent
with open(AI_DIR / "docs.txt", "r", encoding="utf-8") as f:
    sentences = [line.strip() for line in f.readlines() if line.strip()]


# --------------------------
# ğŸ”¥ 3) ì„ë² ë”© ëª¨ë¸ ë¡œë“œ (1íšŒ)
# --------------------------
print("[Embedding] ëª¨ë¸ ë¡œë”© ì¤‘...")
embed_model = SentenceTransformer("all-MiniLM-L6-v2")
vectors = embed_model.encode(sentences)

index = faiss.IndexFlatL2(vectors.shape[1])
index.add(np.array(vectors))
print("[Embedding] ì¤€ë¹„ë¨")


# --------------------------
# ğŸ”¥ 4) Reranker ë¡œë“œ (1íšŒ)
# --------------------------
print("[Reranker] ë¡œë”© ì¤‘...")
reranker = CrossEncoder("cross-encoder/ms-marco-MiniLM-L-6-v2")
print("[Reranker] ì¤€ë¹„ë¨")


# --------------------------
# ğŸ”¥ 5) ìŒì„± ìƒì„± í•¨ìˆ˜
# --------------------------
def tts_generate_memory(text):
    mp3_fp = BytesIO()
    tts = gTTS(text=text, lang='ko')
    tts.write_to_fp(mp3_fp)
    mp3_fp.seek(0)

    audio_base64 = base64.b64encode(mp3_fp.read()).decode('utf-8')
    return audio_base64


# --------------------------
# ğŸ”¥ 6) ê²€ìƒ‰ + Reranking (ë¹ ë¥´ê²Œ ë™ì‘)
# --------------------------
def search_relevant_docs(caffeine, screen_time, sleep_time, top_k=5):
    query = f"""
    ì¹´í˜ì¸ {caffeine}mg, ìŠ¤í¬ë¦°íƒ€ì„ {screen_time}ì‹œê°„, 
    ìˆ˜ë©´ {sleep_time}ì‹œê°„ì´ ìˆ˜ë©´ ê±´ê°•ì— ë¯¸ì¹˜ëŠ” ê³¼í•™ì  ì˜í–¥ ìš”ì•½
    """

    q_vec = embed_model.encode([query])
    _, idx = index.search(q_vec, top_k)

    candidates = [sentences[i] for i in idx[0]]

    pairs = [[query, c] for c in candidates]
    scores = reranker.predict(pairs)

    ranked = sorted(zip(candidates, scores), key=lambda x: x[1], reverse=True)
    return [r[0] for r in ranked[:3]]


# --------------------------
# ğŸ”¥ 7) ë…¼ë¬¸ ìš”ì•½ (Gemini í˜¸ì¶œ)
# --------------------------
def summarize_docs(doc_list):
    docs = "\n".join(doc_list)
    prompt = f"""
    ë‹¤ìŒ ì—°êµ¬ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ 'ìˆ˜ë©´ ê³¼í•™ í•µì‹¬ ìš”ì 'ì„ 3ì¤„ë¡œ ì •ë¦¬í•´ì¤˜.

    ì—°êµ¬ ë‚´ìš©:
    {docs}

    ìš”ì•½ í˜•ì‹:
    - (ê³¼í•™ ê·¼ê±°)
    - (ì‹ ì²´/í˜¸ë¥´ëª¬)
    - (í–‰ë™ ìŠµê´€ ì˜í–¥)
    """
    return model.generate_content(prompt).text.strip()


# --------------------------
# ğŸ”¥ 8) ì‹¤ì œ ë¶„ì„ í•¨ìˆ˜ (ë§¤ ìš”ì²­ë§ˆë‹¤ ë¹ ë¥´ê²Œ ì‹¤í–‰ë¨)
# --------------------------
def run_feedback_api(user_name, caffeine, screen_time, sleep_time, style="ì¹œê·¼í•˜ê²Œ"):

    docs = search_relevant_docs(caffeine, screen_time, sleep_time)
    summarized = summarize_docs(docs)

    # ì‚¬ìš©ì ìŠ¤íƒ€ì¼ ë°˜ì˜
    tone = {
        "ì¹œê·¼í•˜ê²Œ": "ì¹œê·¼í•˜ê³  ë¶€ë“œëŸ½ê²Œ ì„¤ëª…í•´ì¤˜.",
        "ì „ë¬¸ê°€ì²˜ëŸ¼": "ì „ë¬¸ê°€ ë§íˆ¬ë¡œ ì„¤ëª…í•´ì¤˜.",
        "ìœ ë¨¸ ì„ì–´ì„œ": "ìœ ë¨¸ëŸ¬ìŠ¤í•˜ê²Œ ë§í•´ì¤˜.",
    }.get(style, "ì¹œê·¼í•˜ê²Œ ì„¤ëª…í•´ì¤˜.")

    prompt = f"""
    ë‹¹ì‹ ì€ ìˆ˜ë©´ ê³¼í•™ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

    â–¼ ì—°êµ¬ ìš”ì•½
    {summarized}

    â–¼ ì‚¬ìš©ì ì •ë³´
    - ì´ë¦„: {user_name}
    - ì¹´í˜ì¸ ì„­ì·¨: {caffeine}mg
    - ìŠ¤í¬ë¦°íƒ€ì„: {screen_time}ì‹œê°„
    - ìˆ˜ë©´ì‹œê°„: {sleep_time}ì‹œê°„

    â–¼ ìš”êµ¬ì‚¬í•­
    ìœ„ ì—°êµ¬ ê¸°ë°˜ìœ¼ë¡œ, ì‚¬ìš©ìì˜ ìƒí™œ íŒ¨í„´ì„ ë¶„ì„í•˜ê³  {tone}
    - í•µì‹¬ ìš”ì ë§Œ 2~3ë¬¸ì¥ìœ¼ë¡œ ì •ë¦¬í•´ì¤˜.
    - ì¤‘ë³µ ì—†ì´ ê¹”ë”í•˜ê²Œ ë§í•´ì¤˜.
    """

    answer = model.generate_content(prompt).text.strip()
    return answer
